{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import torch.nn as nn\n",
    "np.random.seed(42)\n",
    "import torch\n",
    "torch.manual_seed(42)\n",
    "from scipy.stats import spearmanr\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入数据\n",
    "y_label = 'y3_label'\n",
    "raw_data_path = '/home/laiminzhi/data/xydata/'\n",
    "xydata = pd.read_hdf(raw_data_path+'xy_data_2836.h5')\n",
    "xydata.index = xydata.index.set_names(['code1','date','code'], level=[0, 1,2])\n",
    "# 删除不需要的索引层\n",
    "xydata = xydata.droplevel('code1')\n",
    "\n",
    "xydata_limit = pd.read_hdf(raw_data_path+'xy_data_2836_udlimit.h5')\n",
    "selected_feature = pd.read_csv('selected_feature.csv',index_col=0)['AlphaName'].to_list()\n",
    "\n",
    "xydata = xydata.loc[:,[y_label]+selected_feature]\n",
    "# 把xydata_limit的ud_limit_h2列加到xydata中\n",
    "xydata = xydata.join(xydata_limit['ud_limit_h2'])\n",
    "xydata_final = xydata[xydata['ud_limit_h2']!=1]\n",
    "\n",
    "#除去inf\n",
    "xydata_final = xydata_final.replace([np.inf, -np.inf], 0.0)\n",
    "\n",
    "xydata_final = xydata_final.drop(columns='ud_limit_h2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xydata_final = xydata_final.sort_index(level='date')\n",
    "train = xydata_final.loc[:'20211231',]\n",
    "test = xydata_final.loc['20220104':,]\n",
    "\n",
    "y_train = train[y_label].values\n",
    "y_test = test[y_label].values\n",
    "\n",
    "X_train = train.drop(y_label,axis=1).values\n",
    "\n",
    "X_test = test.drop(y_label,axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y3_label    0.011725\n",
      "x_62        0.000000\n",
      "x_204       0.000000\n",
      "x_240       0.000000\n",
      "x_114       0.000000\n",
      "              ...   \n",
      "x_152       0.000000\n",
      "x_128       0.000000\n",
      "x_176       0.000000\n",
      "x_119       0.000000\n",
      "x_215       0.000000\n",
      "Name: (20180102, 000032.SZ), Length: 72, dtype: float64\n",
      "y3_label   -0.023619\n",
      "x_62        0.000190\n",
      "x_204       0.321479\n",
      "x_240       0.028028\n",
      "x_114      -0.283466\n",
      "              ...   \n",
      "x_152       0.292579\n",
      "x_128       0.292579\n",
      "x_176      -0.083632\n",
      "x_119      -0.045022\n",
      "x_215      -0.045022\n",
      "Name: (20180102, 000731.SZ), Length: 72, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#train中第19和第186行数据\n",
    "train_row_19 = train.iloc[19,:]\n",
    "train_row_186 = train.iloc[186,:]\n",
    "print(train_row_19)\n",
    "print(train_row_186)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (hidden1): Linear(in_features=71, out_features=50, bias=True)\n",
      "  (hidden2): Linear(in_features=50, out_features=50, bias=True)\n",
      "  (output): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (silu): SiLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.hidden1 = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        self.hidden2 = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "        self.output = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.silu = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.silu(self.hidden1(x))\n",
    "        x = self.silu(self.hidden2(x))\n",
    "        x = self.output(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# 创建模型实例\n",
    "# 假设输入大小为10，输出大小为1\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "\n",
    "model = MLP(input_size, hidden_size, output_size)\n",
    "\n",
    "# 打印模型结构\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练以上模型\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "epochs = 30\n",
    "patience = 10\n",
    "\n",
    "k_folds = 2\n",
    "\n",
    "batch_size = 3000\n",
    "\n",
    "kf = KFold(n_splits=k_folds, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"model1\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 划分训练集和验证集\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 0.2743\n",
      "model saved!\n",
      "Epoch [1/30], Validation Loss: 0.0785\n",
      "Epoch [2/30], Loss: 0.0493\n",
      "model saved!\n",
      "Epoch [2/30], Validation Loss: 0.0291\n",
      "Epoch [3/30], Loss: 0.1142\n",
      "model saved!\n",
      "Epoch [3/30], Validation Loss: 0.0139\n",
      "Epoch [4/30], Loss: 0.0637\n",
      "1\n",
      "Epoch [4/30], Validation Loss: 0.0725\n",
      "Epoch [5/30], Loss: 0.1962\n",
      "2\n",
      "Epoch [5/30], Validation Loss: 0.0681\n",
      "Epoch [6/30], Loss: 0.0357\n",
      "model saved!\n",
      "Epoch [6/30], Validation Loss: 0.0021\n",
      "Epoch [7/30], Loss: 0.1336\n",
      "1\n",
      "Epoch [7/30], Validation Loss: 0.0021\n",
      "Epoch [8/30], Loss: 0.0059\n",
      "model saved!\n",
      "Epoch [8/30], Validation Loss: 0.0014\n",
      "Epoch [9/30], Loss: 0.0031\n",
      "model saved!\n",
      "Epoch [9/30], Validation Loss: 0.0013\n",
      "Epoch [10/30], Loss: 0.0065\n",
      "model saved!\n",
      "Epoch [10/30], Validation Loss: 0.0013\n",
      "Epoch [11/30], Loss: 0.0055\n",
      "model saved!\n",
      "Epoch [11/30], Validation Loss: 0.0013\n",
      "Epoch [12/30], Loss: 0.0110\n",
      "1\n",
      "Epoch [12/30], Validation Loss: 0.0024\n",
      "Epoch [13/30], Loss: 0.0033\n",
      "2\n",
      "Epoch [13/30], Validation Loss: 0.0022\n",
      "Epoch [14/30], Loss: 0.1173\n",
      "3\n",
      "Epoch [14/30], Validation Loss: 0.0484\n",
      "Epoch [15/30], Loss: 0.1872\n",
      "4\n",
      "Epoch [15/30], Validation Loss: 0.0317\n",
      "Epoch [16/30], Loss: 0.0493\n",
      "5\n",
      "Epoch [16/30], Validation Loss: 0.0045\n",
      "Epoch [17/30], Loss: 0.0146\n",
      "6\n",
      "Epoch [17/30], Validation Loss: 0.0049\n",
      "Epoch [18/30], Loss: 0.1309\n",
      "7\n",
      "Epoch [18/30], Validation Loss: 0.0169\n",
      "Epoch [19/30], Loss: 0.1060\n",
      "8\n",
      "Epoch [19/30], Validation Loss: 0.0041\n",
      "186\n",
      "loss: 4.5714425727331455e+23\n",
      "invalid_pred_index: (tensor([], device='cuda:0', dtype=torch.int64),)\n",
      "invalid_X_train_tensor: tensor([], device='cuda:0', size=(0, 71))\n",
      "invalid_Y_train_tensor: tensor([], device='cuda:0')\n",
      "invalid_Y_pred: tensor([], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Epoch [20/30], Loss: 695805566626049556480.0000\n",
      "9\n",
      "Epoch [20/30], Validation Loss: 1029320617266507022336.0000\n",
      "19\n",
      "loss: 7.68310043189742e+22\n",
      "invalid_pred_index: (tensor([], device='cuda:0', dtype=torch.int64),)\n",
      "invalid_X_train_tensor: tensor([], device='cuda:0', size=(0, 71))\n",
      "invalid_Y_train_tensor: tensor([], device='cuda:0')\n",
      "invalid_Y_pred: tensor([], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "186\n",
      "loss: 6.187785199572357e+23\n",
      "invalid_pred_index: (tensor([], device='cuda:0', dtype=torch.int64),)\n",
      "invalid_X_train_tensor: tensor([], device='cuda:0', size=(0, 71))\n",
      "invalid_Y_train_tensor: tensor([], device='cuda:0')\n",
      "invalid_Y_pred: tensor([], device='cuda:0', grad_fn=<IndexBackward0>)\n",
      "Epoch [21/30], Loss: 1058766399202754822144.0000\n",
      "10\n",
      " The training stops early in epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train,dtype=torch.float32,device=device)\n",
    "Y_train_tensor = torch.tensor(y_train,dtype=torch.float32,device=device)\n",
    "\n",
    "X_val_tensor = torch.tensor(X_train,dtype=torch.float32,device=device)\n",
    "Y_val_tensor = torch.tensor(y_train,dtype=torch.float32,device=device)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor,Y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_val_tensor,Y_val_tensor)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=False)\n",
    "valid_loader = DataLoader(dataset=valid_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "bad_epoch = 0\n",
    "early_stop_epoch = 0\n",
    "\n",
    "valid_loss_min = float(\"inf\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = []\n",
    "    model.train()\n",
    "    for i,(X_train_tensor,Y_train_tensor) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_train_tensor)\n",
    "        Y_pred = Y_pred.view(-1)\n",
    "        mask  = Y_pred < 100\n",
    "        Y_pred = torch.where(mask, Y_pred, torch.tensor(0,dtype=torch.float32,device=device))\n",
    "        Y_train_tensor = torch.where(mask, Y_train_tensor, torch.tensor(0,dtype=torch.float32,device=device))\n",
    "\n",
    "        loss = criterion(Y_pred,Y_train_tensor)\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        if loss>1000:\n",
    "            print(i)\n",
    "            print(\"loss:\",loss.item())\n",
    "            #找出Y_pred>1000的值对应的index\n",
    "            Y_pred = Y_pred.view(-1)\n",
    "            invalid_pred_index = torch.where(Y_pred>1000)\n",
    "            print(\"invalid_pred_index:\",invalid_pred_index)\n",
    "            invalid_X_train_tensor = X_train_tensor[invalid_pred_index]\n",
    "            invalid_Y_train_tensor = Y_train_tensor[invalid_pred_index]\n",
    "            print(\"invalid_X_train_tensor:\",invalid_X_train_tensor)\n",
    "            print(\"invalid_Y_train_tensor:\",invalid_Y_train_tensor)\n",
    "            print(\"invalid_Y_pred:\",Y_pred[invalid_pred_index])\n",
    "            \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {np.mean(train_loss):.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = []\n",
    "        for X_val_tensor,Y_val_tensor in valid_loader:\n",
    "            Y_pred = model(X_val_tensor)\n",
    "\n",
    "\n",
    "            Y_pred = Y_pred.view(-1)\n",
    "            mask  = Y_pred < 100\n",
    "            Y_pred = torch.where(mask, Y_pred, torch.tensor(0,dtype=torch.float32,device=device))\n",
    "            Y_val_tensor = torch.where(mask, Y_val_tensor, torch.tensor(0,dtype=torch.float32,device=device))\n",
    "\n",
    "            test_loss = criterion(Y_pred,Y_val_tensor)\n",
    "            valid_loss.append(test_loss.item())\n",
    "\n",
    "        valid_loss_cur = np.mean(valid_loss)\n",
    "\n",
    "        if valid_loss_cur < valid_loss_min:\n",
    "            valid_loss_min = valid_loss_cur\n",
    "            bad_epoch = 0\n",
    "            early_stop_epoch = epoch\n",
    "            torch.save(model.state_dict(), './mlp_ensemble/model/' + model_name + '.pth')\n",
    "            print(\"model saved!\")\n",
    "        else:\n",
    "            bad_epoch += 1\n",
    "            print(bad_epoch)\n",
    "            if bad_epoch >= patience:    # 如果验证集指标连续patience个epoch没有提升，就停掉训练\n",
    "                print(\" The training stops early in epoch {}\".format(epoch))\n",
    "                torch.save(model.state_dict(), './mlp_ensemble/model/' + model_name + '.pth')\n",
    "                break\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Validation Loss: {np.mean(valid_loss):.4f}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0073842573910951614\n"
     ]
    }
   ],
   "source": [
    "#测试数据\n",
    "model.load_state_dict(torch.load('./mlp_ensemble/model/' + model_name + '.pth'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test,dtype=torch.float32,device=device)\n",
    "    Y_test_tensor = torch.tensor(y_test,dtype=torch.float32,device=device)\n",
    "    y_pred = model(X_test_tensor)\n",
    "    test_loss = criterion(y_pred,Y_test_tensor.view(-1,1))\n",
    "    print(f'Test Loss: {test_loss.item()}')\n",
    "y_pred = y_pred.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank_avg: 0.010176391815162148\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "def calculate_spearman(group):\n",
    "    return spearmanr(group['Y_hat'], group['Y'])[0]\n",
    "\n",
    "#把y_label和y_test还原回dataframe\n",
    "y_test_df = pd.DataFrame(y_test, index=test.index, columns=['Y'])\n",
    "y_pred_df = pd.DataFrame(y_pred, index=test.index, columns=['Y_hat'])\n",
    "result = pd.concat([y_test_df,y_pred_df],axis=1)\n",
    "#计算result的rank ic\n",
    "spearman_correlations = result.groupby(level='date').apply(calculate_spearman)\n",
    "rank_avg = spearman_correlations.mean()\n",
    "print('rank_avg:',rank_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved!\n",
      "alpha: -5.244877101848944\n"
     ]
    }
   ],
   "source": [
    "grouped_df = result.groupby(level='date')\n",
    "    \n",
    "for name,group in grouped_df:\n",
    "    group = group.reset_index(drop=False)\n",
    "    group.to_csv('./mlp_ensemble/prediction/'+model_name+'.csv')\n",
    "print(\"data saved!\")\n",
    "\n",
    "def cal_alpha(XY):\n",
    "    #查看pnl如何计算\n",
    "    d1 = XY.copy()\n",
    "    enterRatio = 0.9\n",
    "    exitRatio = 0.9\n",
    "    ## 1) calculate yestRank;\n",
    "    d1['yestRank'] = d1.groupby('date')['yest'].rank(method='average',na_option='keep',ascending=True,pct=True)\n",
    "    rtnMat = pd.pivot_table(data=d1,index='date',columns='code',values='y',dropna=False)\n",
    "    yestMat = pd.pivot_table(data=d1,index='date',columns='code',values='yest',dropna=False)\n",
    "    yestRankMat = pd.pivot_table(data=d1,index='date',columns='code',values='yestRank',dropna=False).fillna(0)\n",
    "    posiMat = pd.DataFrame(np.full(yestRankMat.shape,fill_value=0),index=yestRankMat.index,columns=yestRankMat.columns)\n",
    "    ud_limitMat = pd.pivot_table(data=d1,index='date',columns='code',values='ud_limit_h2',dropna=False).fillna(0)\n",
    "\n",
    "    ## 2) calPosiMat： ## no buy if up_limit && no sell if down_limit;\n",
    "    for i,row_index in enumerate(posiMat.index):\n",
    "        if (i==0):\n",
    "            continue\n",
    "        flag1 = (yestRankMat.iloc[i,:]>enterRatio)\n",
    "        flag2 = (posiMat.iloc[i-1,:]==0) & (ud_limitMat.iloc[i,:]==1)\n",
    "        posiMat.loc[row_index,(~flag2 & flag1)] = 1\n",
    "\n",
    "        flag3 = (yestRankMat.iloc[i,:]>exitRatio) & (yestRankMat.iloc[i,:]<=enterRatio)\n",
    "        flag4 = (posiMat.iloc[i-1,:]==1)\n",
    "        posiMat.loc[row_index,(flag3 & flag4)] = 1\n",
    "\n",
    "        flag5 = (posiMat.iloc[i-1,:]==1) & (posiMat.iloc[i,:]==0) & (ud_limitMat.iloc[i,:]==-1)\n",
    "        posiMat.loc[row_index,flag5] = 1\n",
    "        \n",
    "        if (i== (posiMat.shape[0]-1)):## position=0 if yest=NA on last day;\n",
    "            flag6 = yestMat.iloc[i,:].isna()\n",
    "            posiMat.loc[row_index,flag6] = 0\n",
    "\n",
    "\n",
    "    pnlMat = rtnMat * posiMat\n",
    "    pnlVec = pnlMat.sum(axis=1)/(posiMat==1).sum(axis=1)\n",
    "    alpha = pnlVec.mean()*1e4\n",
    "    return alpha\n",
    "\n",
    "def get_XY(yest,xy):\n",
    "    #xy是原始xy文件，yest是合并后的预测文件\n",
    "    universe = 'univ_tradable'\n",
    "\n",
    "    XY = xy.loc[xy[universe]==1,:'ud_limit_h4']\n",
    "    XY= XY.rename(columns={'y1':'y'})\n",
    "    XY = pd.merge(XY, yest,on=['date','code'],how='inner')\n",
    "\n",
    "    ##---- 1. benchmark ----##\n",
    "    XY['yest'] = XY['Y_hat']\n",
    "    return XY\n",
    "\n",
    "import os\n",
    "xy = pd.read_hdf(\"/home/laiminzhi/wenbin/DL_stock_combo/data/xy_data/xy_data_new.h5\")\n",
    "all_files = [pd.read_csv(f'./ridgeCV/{f}',\n",
    "                            dtype={'date':str})for f in sorted(os.listdir('./ridgeCV'))]\n",
    "yest = pd.concat(all_files, axis=0) #贴合所有的预测值\n",
    "XY = get_XY(yest,xy)\n",
    "alpha = cal_alpha(XY)\n",
    "print('alpha:',alpha)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
